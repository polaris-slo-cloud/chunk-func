{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0e7ce5-f7d0-4f1e-b917-deaf3466fa73",
   "metadata": {},
   "source": [
    "# Profiling Results Accuracy\n",
    "\n",
    "This file compares the accuracy of the following profiling results:\n",
    "\n",
    "* Baseline: exhaustive profiling (159 resource profiles, based on the complete AWS profiles range in 64 MB steps)\n",
    "* Linear model (linear interpolation between an evenly distributed selection of 5% of the exhaustive profiling results)\n",
    "* Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b2e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Workaround for using the Jupyter container from VS Code Jupyter extension.\n",
    "if not os.path.exists('./profiling-results'):\n",
    "    os.chdir('./chunk-func/jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2591b972-c9fe-4c9b-afd9-4182b091a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import math\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Definitions of our column names.\n",
    "col_profile = 'profile'\n",
    "col_exec_time = 'execTime'\n",
    "col_cost = 'cost'\n",
    "col_profiled = 'profiled'\n",
    "\n",
    "@dataclass\n",
    "class FunctionProfilingResults:\n",
    "    input_sizes: list[int]\n",
    "    '''All input sizes for this function in ascending order.'''\n",
    "    \n",
    "    results: dict[int, pd.DataFrame]\n",
    "    '''The results indexed by input size.'''\n",
    "\n",
    "class FunctionProfilingResultsMap(dict[str, FunctionProfilingResults]):\n",
    "    '''FunctionProfilingResults indexed by function name'''\n",
    "    # Type aliases do not seem to be supported in notebooks, so we inherit from dict.\n",
    "    pass\n",
    "\n",
    "def extract_input_sizes(func_desc) -> list[int]:\n",
    "    ret: list[int] = []\n",
    "    typical_inputs = func_desc['spec']['functionDescription']['typicalInputs']\n",
    "    for input in typical_inputs:\n",
    "        ret.append(input['sizeBytes'])\n",
    "    return ret\n",
    "\n",
    "def add_result(profile_result, dest_results_per_input: dict[int, list[dict[str, object]]]):\n",
    "    profile = profile_result['resourceProfileId']\n",
    "    results = profile_result.get('results')\n",
    "    \n",
    "    if results is not None:\n",
    "        for input_result in results:\n",
    "            results_list = dest_results_per_input[input_result['inputSizeBytes']]\n",
    "            results_list.append({ \n",
    "                col_profile: profile, \n",
    "                col_exec_time: input_result['executionTimeMs'], \n",
    "                col_cost: float(input_result['executionCost']),\n",
    "                col_profiled: input_result.get('resultType', 'Profiled') == 'Profiled',\n",
    "            })\n",
    "\n",
    "\n",
    "def load_result(path: str) -> FunctionProfilingResults:\n",
    "    '''\n",
    "    Reads a FunctionDescription YAML file and returns a dictionary of the profiling results,\n",
    "    indexed by input size.\n",
    "    '''\n",
    "    with open(path, 'r') as file:\n",
    "        func_desc = yaml.safe_load(file)\n",
    "    input_sizes = extract_input_sizes(func_desc)\n",
    "    results_per_input = { \n",
    "        input_size: [] for input_size in input_sizes \n",
    "    }\n",
    "\n",
    "    all_results = func_desc['status']['profilingResults']['results']\n",
    "    for profile_result in all_results:\n",
    "        add_result(profile_result, results_per_input)\n",
    "\n",
    "    data_frames: dict[int, pd.DataFrame] = {}\n",
    "    for input_size, results in results_per_input.items():\n",
    "        df = pd.DataFrame(data=results, columns=[col_profile, col_exec_time, col_cost, col_profiled])\n",
    "        df = df.set_index(col_profile)\n",
    "        data_frames[input_size] = df\n",
    "    return FunctionProfilingResults(input_sizes=input_sizes, results=data_frames)\n",
    "\n",
    "\n",
    "def load_results(functions: list[str], profiling_type: str) -> FunctionProfilingResultsMap:\n",
    "    '''\n",
    "    Loads the results for all specified functions. profiling_type may be 'aws', 'gcf', or 'bo'.\n",
    "    '''\n",
    "    ret = FunctionProfilingResultsMap()\n",
    "    for func in functions:\n",
    "        ret[func] = load_result(f'./profiling-results/{profiling_type}/{func}.yaml')\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97840053-429b-43cb-823e-63cc6bcb99da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_functions = [\n",
    "    # LogPro\n",
    "    'validate-log',\n",
    "    'extract-basic-stats',\n",
    "    'extract-successes',\n",
    "    'extract-success-stats',\n",
    "\n",
    "    # VidPro\n",
    "    'validate-video',   \n",
    "    'cut-video',\n",
    "    'merge-videos',\n",
    "\n",
    "    # FaceDet\n",
    "    'validate-video-face-recog',\n",
    "    'transform-video',\n",
    "    'detect-faces',\n",
    "    'mark-faces',\n",
    "]\n",
    "\n",
    "aws_results = load_results(all_functions, 'aws')\n",
    "exhaustive_results = aws_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337ec354-3023-490c-afa7-fa04b517deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_hyperparams = 'poi=0.02-minSamples=0.1'\n",
    "\n",
    "bo_xi_values = [ '0.01', '0.05', '0.1', '0.5', '1.0', '1.5', '2.0', '2.5', '3.0' ]\n",
    "output_folder = './output/aws-bo'\n",
    "\n",
    "def get_bo_results_dir(bo_xi: str) -> str:\n",
    "    return f'bo/{bo_hyperparams}/xi={bo_xi}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc5645e-1f7d-4c81-a83b-b4d9b0ce756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def matplot_exhaustive_bo_comparison(exhaustive_result: pd.DataFrame, bo_result: pd.DataFrame):\n",
    "    fig, ax = plt.subplots()\n",
    "    exhaustive_result[[col_exec_time]].plot(ax=ax, label='Exhaustive')\n",
    "    bo_result[[col_exec_time]].plot(ax=ax, label='BO')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c68142-3744-42a4-8867-1daf7ba1478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "def seaplot_exhaustive_bo_comparison(exhaustive_result: pd.DataFrame, bo_result: pd.DataFrame, title: str):\n",
    "    exhaustive_result = exhaustive_result[[col_exec_time]].rename(columns={col_exec_time: 'Exhaustive'})\n",
    "    bo_result_renamed = bo_result[[col_exec_time]].rename(columns={col_exec_time: 'BO'})\n",
    "    joined = exhaustive_result.join(bo_result_renamed)\n",
    "    melted = joined.reset_index().melt(id_vars=[col_profile], var_name='type', value_name=col_exec_time)\n",
    "    g: sns.FacetGrid = sns.relplot(\n",
    "        data=melted,\n",
    "        kind='line',\n",
    "        x=col_profile,\n",
    "        y=col_exec_time,\n",
    "        hue='type',\n",
    "        facet_kws=dict(sharex=True),\n",
    "    )\n",
    "    g.set_axis_labels('Profile', 'Execution Time (ms)')\n",
    "    g.set_xticklabels(step=10, rotation=45)\n",
    "    g.ax.set_title(title)\n",
    "\n",
    "    # Mark the samples that BO decided to profile (the others were inferred)\n",
    "    bo_profiled = bo_result[bo_result[col_profiled] == True].copy()\n",
    "    bo_profiled.loc[:, 'type'] = 'BO'\n",
    "    sns.scatterplot(\n",
    "        ax=g.ax,\n",
    "        data=bo_profiled,\n",
    "        x=col_profile,\n",
    "        y=col_exec_time,\n",
    "        hue='type',\n",
    "        style='type',\n",
    "        legend=False,\n",
    "        palette=[(0, 0, 0)],  #[sns.color_palette('flare')[0]],\n",
    "        markers=['X'],\n",
    "        zorder=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8c7f8b-b335-41d3-9ba3-3b6dcb8e65f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RMSE calculation for single functions.\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def normalized_rmse(exhaustive_result: pd.DataFrame, predicted_result: pd.DataFrame) -> float:\n",
    "    '''Computes the normalized RMSE for a single input size.'''\n",
    "    y_exhaustive_df: pd.DataFrame = exhaustive_result[[col_exec_time]]\n",
    "    y_pred_df: pd.DataFrame = predicted_result[[col_exec_time]]\n",
    "\n",
    "    # Due to errors for certain profiles in the exhaustive runs, the two DataFrames might not contain exactly the same profiles,\n",
    "    # e.g., the profiling for 256mib went into timeout, while the predicted results inferred a value for this profile.\n",
    "    # We want to compare only those profiles which are present in both DataFrames.\n",
    "    merged = y_exhaustive_df.merge(y_pred_df, how='inner', on=[col_profile], suffixes=('_exhaustive', '_predicted'))\n",
    "    y_exhaustive = merged[f'{col_exec_time}_exhaustive']\n",
    "    y_pred = merged[f'{col_exec_time}_predicted']\n",
    "\n",
    "    rmse = root_mean_squared_error(y_exhaustive, y_pred)\n",
    "    y_ex_mean = y_exhaustive.mean()\n",
    "    return rmse / y_ex_mean\n",
    "\n",
    "\n",
    "def mean_normalized_rmse(exhaustive_results: FunctionProfilingResults, predicted_results: FunctionProfilingResults) -> float:\n",
    "    '''Computes the normalized RMSE for all input sizes and returns the mean average.'''\n",
    "    rmse_sum = 0.0\n",
    "    for input_size in exhaustive_results.input_sizes: # [exhaustive_results.input_sizes[-3]]:\n",
    "        exhaustive = exhaustive_results.results[input_size]\n",
    "        predicted = predicted_results.results[input_size]\n",
    "        rmse = normalized_rmse(exhaustive_result=exhaustive, predicted_result=predicted)\n",
    "        rmse_sum += rmse\n",
    "    \n",
    "    mean_rmse = rmse_sum / float(len(exhaustive_results.input_sizes))\n",
    "    return mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e1248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean RMSE across all input sizes for all functions.\n",
    "\n",
    "def mean_normalized_rmse_for_all_functions(bo_xi: str, exhaustive_results: FunctionProfilingResultsMap) -> pd.Series:\n",
    "    '''Computes the mean RMSE across all input sizes for all functions.'''\n",
    "    predicted_results = load_results(all_functions, get_bo_results_dir(bo_xi))\n",
    "    rmses: dict[str, float] = {}\n",
    "    for key, exhaustive_result in exhaustive_results.items():\n",
    "        predicted_result = predicted_results[key]\n",
    "        rmses[key] = mean_normalized_rmse(exhaustive_results=exhaustive_result, predicted_results=predicted_result)\n",
    "    return pd.Series(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7d999a-5ab7-4fd8-a7fd-e8eaf712953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute RMSE for largest input size and plot results.\n",
    "\n",
    "# bo_xi='0.01'\n",
    "# bo_results = load_results(all_functions, f'bo/poi=0.02-minSamples=0.1/xi={bo_xi}')\n",
    "\n",
    "# print('xi = ', bo_xi)\n",
    "\n",
    "# for key, exhaustive_result in exhaustive_results.items():\n",
    "#     bo_result = bo_results[key]\n",
    "#     # exhaustive_largest_input_result = exhaustive_result.results[exhaustive_result.input_sizes[-1]]\n",
    "#     # bo_largest_input_result = bo_result.results[bo_result.input_sizes[-1]]\n",
    "#     # seaplot_exhaustive_bo_comparison(exhaustive_largest_input_result, bo_largest_input_result, key)\n",
    "#     # rmse = normalized_rmse(exhaustive_largest_input_result, bo_largest_input_result)\n",
    "#     rmse = mean_normalized_rmse(exhaustive_results=exhaustive_result, predicted_results=bo_result)\n",
    "#     print(key, 'RMSE =', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77997654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute mean RMSE across all input sizes.\n",
    "\n",
    "# df_rmse = pd.DataFrame(0.0, exhaustive_results.keys(), bo_xi_values)\n",
    "\n",
    "# for bo_xi in bo_xi_values:\n",
    "#     rmses = mean_normalized_rmse_for_all_functions(bo_xi, exhaustive_results)\n",
    "#     df_rmse[bo_xi] = rmses\n",
    "\n",
    "# display(df_rmse)\n",
    "# df_rmse.to_csv(f'{output_folder}/bo-mean-rmse-{bo_hyperparams}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affcfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of distinct RMSE values for each input size, for all BO xi hyperparameter values.\n",
    "\n",
    "class RmseByInputSizeMap(dict[int, float]):\n",
    "    pass\n",
    "\n",
    "@dataclass\n",
    "class RmseAndBoXiPair:\n",
    "    rmse: float\n",
    "    bo_xi: str\n",
    "\n",
    "@dataclass\n",
    "class RmseInfo(RmseAndBoXiPair):\n",
    "    function: str\n",
    "    input_size: int\n",
    "\n",
    "\n",
    "def load_all_bo_results() -> dict[str, FunctionProfilingResultsMap]:\n",
    "    '''Loads all BO results indexed by bo_xi strings'''\n",
    "    all_bo_results: dict[str, FunctionProfilingResultsMap] = {}\n",
    "    for bo_xi in bo_xi_values:\n",
    "        bo_results = load_results(all_functions, get_bo_results_dir(bo_xi))\n",
    "        all_bo_results[bo_xi] = bo_results\n",
    "    return all_bo_results\n",
    "\n",
    "\n",
    "def normalized_rmse_for_all_input_sizes(exhaustive_results: FunctionProfilingResults, predicted_results: FunctionProfilingResults) -> RmseByInputSizeMap:\n",
    "    '''Returns a dict of normalized RMSEs for every input size, indexed by the input size'''\n",
    "    rmses = RmseByInputSizeMap()\n",
    "    for input_size in exhaustive_results.input_sizes:\n",
    "        exhaustive = exhaustive_results.results[input_size]\n",
    "        predicted = predicted_results.results[input_size]\n",
    "        rmse = normalized_rmse(exhaustive_result=exhaustive, predicted_result=predicted)\n",
    "        rmses[input_size] = rmse\n",
    "    return rmses\n",
    "\n",
    "\n",
    "def normalized_rmse_for_all_bo_xis(fn_name: str, exhaustive_results: FunctionProfilingResults, all_bo_results: dict[str, FunctionProfilingResultsMap]) -> dict[str, RmseByInputSizeMap]:\n",
    "    '''Calculates all normalized RMSEs for every input size for all BO results and returns them indexed by bo_xi value'''\n",
    "    bo_rmses: dict[str, RmseByInputSizeMap] = {}\n",
    "    for bo_xi in bo_xi_values:\n",
    "        predicted_results = all_bo_results[bo_xi][fn_name]\n",
    "        rmses = normalized_rmse_for_all_input_sizes(exhaustive_results=exhaustive_results, predicted_results=predicted_results)\n",
    "        bo_rmses[bo_xi] = rmses\n",
    "    return bo_rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272dde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted list of RMSEs grouped by input sizes.\n",
    "    \n",
    "def convert_to_list(fn_name: str, rmses_by_xi: dict[str, RmseByInputSizeMap]) -> list[RmseInfo]:\n",
    "    ret: list[RmseInfo] = []\n",
    "    for bo_xi, rmses_by_input in rmses_by_xi.items():\n",
    "        for input_size, rmse in rmses_by_input.items():\n",
    "            info = RmseInfo(rmse=rmse, bo_xi=bo_xi, function=fn_name, input_size=input_size)\n",
    "            ret.append(info)\n",
    "    return ret\n",
    "\n",
    "def rmses_for_all_functions(exhaustive_results: FunctionProfilingResultsMap) -> list[RmseInfo]:\n",
    "    all_bo_results = load_all_bo_results()\n",
    "    rmses: list[RmseInfo] = []\n",
    "    for fn_name, fn_exhaustive_results in exhaustive_results.items():\n",
    "        rmses_by_xi = normalized_rmse_for_all_bo_xis(fn_name, fn_exhaustive_results, all_bo_results)\n",
    "        fn_rmses = convert_to_list(fn_name, rmses_by_xi)\n",
    "        rmses += fn_rmses\n",
    "    return rmses\n",
    "\n",
    "\n",
    "def sorted_rmses_for_all_functions(exhaustive_results: FunctionProfilingResultsMap) -> pd.DataFrame:\n",
    "    rmses = rmses_for_all_functions(exhaustive_results)\n",
    "    df = pd.DataFrame(rmses)\n",
    "    df.sort_values(by=['function', 'input_size', 'rmse'], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "618fda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min RMSE for each BO xi value.\n",
    "\n",
    "def find_min_rmse(fn_name: str, exhaustive_results: FunctionProfilingResults, all_bo_results: dict[str, FunctionProfilingResultsMap]) -> dict[int, RmseAndBoXiPair]:\n",
    "    '''Finds the min RMSE and associated bo_xi value for every input size and returns them indexed by input size'''\n",
    "    min_rmses: dict[int, RmseAndBoXiPair] = {}\n",
    "    bo_rmses = normalized_rmse_for_all_bo_xis(fn_name, exhaustive_results, all_bo_results)\n",
    "\n",
    "    for input_size in exhaustive_results.input_sizes:\n",
    "        min_rmse = math.inf\n",
    "        min_rmse_bo_xi: str = None\n",
    "        for bo_xi, rmses in bo_rmses.items():\n",
    "            rmse = rmses[input_size]\n",
    "            if rmse < min_rmse:\n",
    "                min_rmse = rmse\n",
    "                min_rmse_bo_xi = bo_xi\n",
    "        min_rmses[input_size] = RmseAndBoXiPair(rmse=min_rmse, bo_xi=min_rmse_bo_xi)\n",
    "    \n",
    "    return min_rmses\n",
    "\n",
    "\n",
    "def find_min_rmses_for_all_functions(exhaustive_results: FunctionProfilingResultsMap) -> dict[str, dict[int, RmseAndBoXiPair]]:\n",
    "    all_bo_results = load_all_bo_results()\n",
    "    all_min_rmses: dict[str, dict[int, RmseAndBoXiPair]] = {}\n",
    "    for fn_name, fn_exhaustive_results in exhaustive_results.items():\n",
    "        fn_min_rmse = find_min_rmse(fn_name, fn_exhaustive_results, all_bo_results)\n",
    "        all_min_rmses[fn_name] = fn_min_rmse\n",
    "        print('Min RMSE for ', fn_name)\n",
    "        display(fn_min_rmse)\n",
    "    return all_min_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7bada8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>bo_xi</th>\n",
       "      <th>function</th>\n",
       "      <th>input_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.187651</td>\n",
       "      <td>0.01</td>\n",
       "      <td>cut-video</td>\n",
       "      <td>8450897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.187651</td>\n",
       "      <td>0.05</td>\n",
       "      <td>cut-video</td>\n",
       "      <td>8450897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.187651</td>\n",
       "      <td>0.1</td>\n",
       "      <td>cut-video</td>\n",
       "      <td>8450897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.187651</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cut-video</td>\n",
       "      <td>8450897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.187651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cut-video</td>\n",
       "      <td>8450897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.121326</td>\n",
       "      <td>1.5</td>\n",
       "      <td>validate-video-face-recog</td>\n",
       "      <td>1620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.121509</td>\n",
       "      <td>3.0</td>\n",
       "      <td>validate-video-face-recog</td>\n",
       "      <td>1620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.121623</td>\n",
       "      <td>2.0</td>\n",
       "      <td>validate-video-face-recog</td>\n",
       "      <td>1620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.122406</td>\n",
       "      <td>2.5</td>\n",
       "      <td>validate-video-face-recog</td>\n",
       "      <td>1620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.122430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>validate-video-face-recog</td>\n",
       "      <td>1620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse bo_xi                   function  input_size\n",
       "135  0.187651  0.01                  cut-video     8450897\n",
       "144  0.187651  0.05                  cut-video     8450897\n",
       "153  0.187651   0.1                  cut-video     8450897\n",
       "162  0.187651   0.5                  cut-video     8450897\n",
       "171  0.187651   1.0                  cut-video     8450897\n",
       "..        ...   ...                        ...         ...\n",
       "296  0.121326   1.5  validate-video-face-recog     1620000\n",
       "314  0.121509   3.0  validate-video-face-recog     1620000\n",
       "302  0.121623   2.0  validate-video-face-recog     1620000\n",
       "308  0.122406   2.5  validate-video-face-recog     1620000\n",
       "290  0.122430   1.0  validate-video-face-recog     1620000\n",
       "\n",
       "[477 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Find the bo_xi values that have the minimum RMSE for each input size of a function.\n",
    "# find_min_rmses_for_all_functions(exhaustive_results)\n",
    "\n",
    "## Find all RMSEs and print them in a sorted table.\n",
    "df_rmses = sorted_rmses_for_all_functions(exhaustive_results)\n",
    "df_rmses.to_csv(f'{output_folder}/bo-rmses-{bo_hyperparams}.csv')\n",
    "display(df_rmses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
