{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0e7ce5-f7d0-4f1e-b917-deaf3466fa73",
   "metadata": {},
   "source": [
    "# Profiling Results Accuracy\n",
    "\n",
    "This file compares the accuracy of the following profiling results:\n",
    "\n",
    "* Baseline: exhaustive profiling (159 resource profiles, based on the complete AWS profiles range in 64 MB steps)\n",
    "* Linear model (linear interpolation between an evenly distributed selection of 5% of the exhaustive profiling results)\n",
    "* Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b2e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Workaround for using the Jupyter container from VS Code Jupyter extension.\n",
    "if not os.path.exists('./profiling-results'):\n",
    "    os.chdir('./chunk-func/jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2591b972-c9fe-4c9b-afd9-4182b091a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Definitions of our column names.\n",
    "col_profile = 'profile'\n",
    "col_exec_time = 'execTime'\n",
    "col_cost = 'cost'\n",
    "col_profiled = 'profiled'\n",
    "\n",
    "@dataclass\n",
    "class FunctionProfilingResults:\n",
    "    input_sizes: list[int]\n",
    "    '''All input sizes for this function in ascending order.'''\n",
    "    \n",
    "    results: dict[int, pd.DataFrame]\n",
    "    '''The results indexed by input size.'''\n",
    "\n",
    "\n",
    "def extract_input_sizes(func_desc) -> list[int]:\n",
    "    ret: list[int] = []\n",
    "    typical_inputs = func_desc['spec']['functionDescription']['typicalInputs']\n",
    "    for input in typical_inputs:\n",
    "        ret.append(input['sizeBytes'])\n",
    "    return ret\n",
    "\n",
    "def add_result(profile_result, dest_results_per_input: dict[int, list[dict[str, object]]]):\n",
    "    profile = profile_result['resourceProfileId']\n",
    "    results = profile_result.get('results')\n",
    "    \n",
    "    if results is not None:\n",
    "        for input_result in results:\n",
    "            results_list = dest_results_per_input[input_result['inputSizeBytes']]\n",
    "            results_list.append({ \n",
    "                col_profile: profile, \n",
    "                col_exec_time: input_result['executionTimeMs'], \n",
    "                col_cost: float(input_result['executionCost']),\n",
    "                col_profiled: input_result.get('resultType', 'Profiled') == 'Profiled',\n",
    "            })\n",
    "\n",
    "\n",
    "def load_result(path: str) -> FunctionProfilingResults:\n",
    "    '''\n",
    "    Reads a FunctionDescription YAML file and returns a dictionary of the profiling results,\n",
    "    indexed by input size.\n",
    "    '''\n",
    "    with open(path, 'r') as file:\n",
    "        func_desc = yaml.safe_load(file)\n",
    "    input_sizes = extract_input_sizes(func_desc)\n",
    "    results_per_input = { \n",
    "        input_size: [] for input_size in input_sizes \n",
    "    }\n",
    "\n",
    "    all_results = func_desc['status']['profilingResults']['results']\n",
    "    for profile_result in all_results:\n",
    "        add_result(profile_result, results_per_input)\n",
    "\n",
    "    data_frames: dict[int, pd.DataFrame] = {}\n",
    "    for input_size, results in results_per_input.items():\n",
    "        df = pd.DataFrame(data=results, columns=[col_profile, col_exec_time, col_cost, col_profiled])\n",
    "        df = df.set_index(col_profile)\n",
    "        data_frames[input_size] = df\n",
    "    return FunctionProfilingResults(input_sizes=input_sizes, results=data_frames)\n",
    "\n",
    "\n",
    "def load_results(functions: list[str], profiling_type: str) -> dict[str, FunctionProfilingResults]:\n",
    "    '''\n",
    "    Loads the results for all specified functions. profiling_type may be 'aws', 'gcf', or 'bo'.\n",
    "    '''\n",
    "    ret: dict[str, dict[int, pd.DataFrame]] = {\n",
    "        func: load_result(f'./profiling-results/{profiling_type}/{func}.yaml') for func in functions\n",
    "    }\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97840053-429b-43cb-823e-63cc6bcb99da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_functions = [\n",
    "    # LogPro\n",
    "    'validate-log',\n",
    "    'extract-basic-stats',\n",
    "    'extract-successes',\n",
    "    'extract-success-stats',\n",
    "\n",
    "    # VidPro\n",
    "    'validate-video',   \n",
    "    'cut-video',\n",
    "    'merge-videos',\n",
    "\n",
    "    # FaceDet\n",
    "    'validate-video-face-recog',\n",
    "    'transform-video',\n",
    "    'detect-faces',\n",
    "    'mark-faces',\n",
    "]\n",
    "\n",
    "aws_results = load_results(all_functions, 'aws')\n",
    "exhaustive_results = aws_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337ec354-3023-490c-afa7-fa04b517deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_hyperparams = 'poi=0.02-minSamples=0.1'\n",
    "\n",
    "bo_xi_values = [ '0.01', '0.05', '0.1', '0.5', '1.0', '1.5', '2.0', '2.5', '3.0' ]\n",
    "output_folder = './output/aws-bo'\n",
    "\n",
    "def get_bo_results_dir(bo_xi: str) -> str:\n",
    "    return f'bo/{bo_hyperparams}/xi={bo_xi}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc5645e-1f7d-4c81-a83b-b4d9b0ce756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def matplot_exhaustive_bo_comparison(exhaustive_result: pd.DataFrame, bo_result: pd.DataFrame):\n",
    "    fig, ax = plt.subplots()\n",
    "    exhaustive_result[[col_exec_time]].plot(ax=ax, label='Exhaustive')\n",
    "    bo_result[[col_exec_time]].plot(ax=ax, label='BO')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c68142-3744-42a4-8867-1daf7ba1478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "def seaplot_exhaustive_bo_comparison(exhaustive_result: pd.DataFrame, bo_result: pd.DataFrame, title: str):\n",
    "    exhaustive_result = exhaustive_result[[col_exec_time]].rename(columns={col_exec_time: 'Exhaustive'})\n",
    "    bo_result_renamed = bo_result[[col_exec_time]].rename(columns={col_exec_time: 'BO'})\n",
    "    joined = exhaustive_result.join(bo_result_renamed)\n",
    "    melted = joined.reset_index().melt(id_vars=[col_profile], var_name='type', value_name=col_exec_time)\n",
    "    g: sns.FacetGrid = sns.relplot(\n",
    "        data=melted,\n",
    "        kind='line',\n",
    "        x=col_profile,\n",
    "        y=col_exec_time,\n",
    "        hue='type',\n",
    "        facet_kws=dict(sharex=True),\n",
    "    )\n",
    "    g.set_axis_labels('Profile', 'Execution Time (ms)')\n",
    "    g.set_xticklabels(step=10, rotation=45)\n",
    "    g.ax.set_title(title)\n",
    "\n",
    "    # Mark the samples that BO decided to profile (the others were inferred)\n",
    "    bo_profiled = bo_result[bo_result[col_profiled] == True].copy()\n",
    "    bo_profiled.loc[:, 'type'] = 'BO'\n",
    "    sns.scatterplot(\n",
    "        ax=g.ax,\n",
    "        data=bo_profiled,\n",
    "        x=col_profile,\n",
    "        y=col_exec_time,\n",
    "        hue='type',\n",
    "        style='type',\n",
    "        legend=False,\n",
    "        palette=[(0, 0, 0)],  #[sns.color_palette('flare')[0]],\n",
    "        markers=['X'],\n",
    "        zorder=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8c7f8b-b335-41d3-9ba3-3b6dcb8e65f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def normalized_rmse(exhaustive_result: pd.DataFrame, predicted_result: pd.DataFrame) -> float:\n",
    "    '''Computes the normalized RMSE for a single input size.'''\n",
    "    y_exhaustive_df: pd.DataFrame = exhaustive_result[[col_exec_time]]\n",
    "    y_pred_df: pd.DataFrame = predicted_result[[col_exec_time]]\n",
    "\n",
    "    # Due to errors for certain profiles in the exhaustive runs, the two DataFrames might not contain exactly the same profiles,\n",
    "    # e.g., the profiling for 256mib went into timeout, while the predicted results inferred a value for this profile.\n",
    "    # We want to compare only those profiles which are present in both DataFrames.\n",
    "    merged = y_exhaustive_df.merge(y_pred_df, how='inner', on=[col_profile], suffixes=('_exhaustive', '_predicted'))\n",
    "    y_exhaustive = merged[f'{col_exec_time}_exhaustive']\n",
    "    y_pred = merged[f'{col_exec_time}_predicted']\n",
    "\n",
    "    rmse = root_mean_squared_error(y_exhaustive, y_pred)\n",
    "    y_ex_mean = y_exhaustive.mean()\n",
    "    return rmse / y_ex_mean\n",
    "\n",
    "\n",
    "def mean_normalized_rmse(exhaustive_results: FunctionProfilingResults, predicted_results: FunctionProfilingResults) -> float:\n",
    "    '''Computes the normalized RMSE for all input sizes and returns the mean average.'''\n",
    "    rmse_sum = 0.0\n",
    "    for input_size in exhaustive_results.input_sizes:\n",
    "        exhaustive = exhaustive_results.results[input_size]\n",
    "        predicted = predicted_results.results[input_size]\n",
    "        rmse = normalized_rmse(exhaustive_result=exhaustive, predicted_result=predicted)\n",
    "        rmse_sum += rmse\n",
    "    \n",
    "    mean_rmse = rmse_sum / float(len(exhaustive_results.input_sizes))\n",
    "    return mean_rmse\n",
    "    \n",
    "\n",
    "def mean_normalized_rmse_for_all(bo_xi: str, exhaustive_results: dict[str, FunctionProfilingResults]) -> pd.Series:\n",
    "    predicted_results = load_results(all_functions, get_bo_results_dir(bo_xi))\n",
    "    rmses: dict[str, float] = {}\n",
    "    for key, exhaustive_result in exhaustive_results.items():\n",
    "        predicted_result = predicted_results[key]\n",
    "        rmses[key] = mean_normalized_rmse(exhaustive_results=exhaustive_result, predicted_results=predicted_result)\n",
    "    return pd.Series(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7d999a-5ab7-4fd8-a7fd-e8eaf712953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo_xi='0.01'\n",
    "# bo_results = load_results(all_functions, f'bo/poi=0.02-minSamples=0.1/xi={bo_xi}')\n",
    "\n",
    "# print('xi = ', bo_xi)\n",
    "\n",
    "# for key, exhaustive_result in exhaustive_results.items():\n",
    "#     bo_result = bo_results[key]\n",
    "#     # exhaustive_largest_input_result = exhaustive_result.results[exhaustive_result.input_sizes[-1]]\n",
    "#     # bo_largest_input_result = bo_result.results[bo_result.input_sizes[-1]]\n",
    "#     # seaplot_exhaustive_bo_comparison(exhaustive_largest_input_result, bo_largest_input_result, key)\n",
    "#     # rmse = normalized_rmse(exhaustive_largest_input_result, bo_largest_input_result)\n",
    "#     rmse = mean_normalized_rmse(exhaustive_results=exhaustive_result, predicted_results=bo_result)\n",
    "#     print(key, 'RMSE =', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77997654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>validate-log</th>\n",
       "      <td>0.105166</td>\n",
       "      <td>0.106051</td>\n",
       "      <td>0.099868</td>\n",
       "      <td>0.099864</td>\n",
       "      <td>0.101862</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.101842</td>\n",
       "      <td>0.102841</td>\n",
       "      <td>0.102314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extract-basic-stats</th>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.030661</td>\n",
       "      <td>0.030764</td>\n",
       "      <td>0.030811</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.031755</td>\n",
       "      <td>0.031310</td>\n",
       "      <td>0.031367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extract-successes</th>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.065637</td>\n",
       "      <td>0.076864</td>\n",
       "      <td>0.070812</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.069596</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.076138</td>\n",
       "      <td>0.074701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extract-success-stats</th>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>0.055912</td>\n",
       "      <td>0.063086</td>\n",
       "      <td>0.055645</td>\n",
       "      <td>0.057413</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>0.061017</td>\n",
       "      <td>0.064382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate-video</th>\n",
       "      <td>0.223326</td>\n",
       "      <td>0.223880</td>\n",
       "      <td>0.240435</td>\n",
       "      <td>0.234738</td>\n",
       "      <td>0.240961</td>\n",
       "      <td>0.223222</td>\n",
       "      <td>0.219121</td>\n",
       "      <td>0.233723</td>\n",
       "      <td>0.240863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut-video</th>\n",
       "      <td>0.153354</td>\n",
       "      <td>0.121151</td>\n",
       "      <td>0.163987</td>\n",
       "      <td>0.145784</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.121620</td>\n",
       "      <td>0.123166</td>\n",
       "      <td>0.131395</td>\n",
       "      <td>0.123336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge-videos</th>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.058043</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.061704</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.076705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate-video-face-recog</th>\n",
       "      <td>0.187594</td>\n",
       "      <td>0.163918</td>\n",
       "      <td>0.168884</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>0.203967</td>\n",
       "      <td>0.204345</td>\n",
       "      <td>0.203782</td>\n",
       "      <td>0.205785</td>\n",
       "      <td>0.204363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform-video</th>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.165738</td>\n",
       "      <td>0.170036</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>0.168188</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>0.164923</td>\n",
       "      <td>0.162230</td>\n",
       "      <td>0.163394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect-faces</th>\n",
       "      <td>0.127132</td>\n",
       "      <td>0.138157</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>0.139804</td>\n",
       "      <td>0.114572</td>\n",
       "      <td>0.121764</td>\n",
       "      <td>0.138161</td>\n",
       "      <td>0.112609</td>\n",
       "      <td>0.127609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark-faces</th>\n",
       "      <td>0.049988</td>\n",
       "      <td>0.061659</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.041303</td>\n",
       "      <td>0.047999</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>0.072434</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.044488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0.01      0.05       0.1       0.5       1.0  \\\n",
       "validate-log               0.105166  0.106051  0.099868  0.099864  0.101862   \n",
       "extract-basic-stats        0.033351  0.027640  0.030661  0.030764  0.030811   \n",
       "extract-successes          0.065600  0.065637  0.076864  0.070812  0.074912   \n",
       "extract-success-stats      0.055046  0.052493  0.055912  0.063086  0.055645   \n",
       "validate-video             0.223326  0.223880  0.240435  0.234738  0.240961   \n",
       "cut-video                  0.153354  0.121151  0.163987  0.145784  0.130357   \n",
       "merge-videos               0.070553  0.058043  0.062447  0.048692  0.064652   \n",
       "validate-video-face-recog  0.187594  0.163918  0.168884  0.177631  0.203967   \n",
       "transform-video            0.169200  0.165738  0.170036  0.172830  0.168188   \n",
       "detect-faces               0.127132  0.138157  0.121491  0.139804  0.114572   \n",
       "mark-faces                 0.049988  0.061659  0.047337  0.041303  0.047999   \n",
       "\n",
       "                                1.5       2.0       2.5       3.0  \n",
       "validate-log               0.102448  0.101842  0.102841  0.102314  \n",
       "extract-basic-stats        0.030596  0.031755  0.031310  0.031367  \n",
       "extract-successes          0.069596  0.075700  0.076138  0.074701  \n",
       "extract-success-stats      0.057413  0.064096  0.061017  0.064382  \n",
       "validate-video             0.223222  0.219121  0.233723  0.240863  \n",
       "cut-video                  0.121620  0.123166  0.131395  0.123336  \n",
       "merge-videos               0.059227  0.061704  0.069395  0.076705  \n",
       "validate-video-face-recog  0.204345  0.203782  0.205785  0.204363  \n",
       "transform-video            0.169615  0.164923  0.162230  0.163394  \n",
       "detect-faces               0.121764  0.138161  0.112609  0.127609  \n",
       "mark-faces                 0.054912  0.072434  0.046407  0.044488  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rmse = pd.DataFrame(0.0, exhaustive_results.keys(), bo_xi_values)\n",
    "\n",
    "for bo_xi in bo_xi_values:\n",
    "    rmses = mean_normalized_rmse_for_all(bo_xi, exhaustive_results)\n",
    "    df_rmse[bo_xi] = rmses\n",
    "\n",
    "display(df_rmse)\n",
    "df_rmse.to_csv(f'{output_folder}/bo-mean-rmse-{bo_hyperparams}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
